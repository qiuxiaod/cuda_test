
Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<46>;
.reg .f32 %f<29>;
.reg .b64 %rd<18>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[32768];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd7, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd8, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r17, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r18, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r17], %r18;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r24, %r2, 128;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r4, [%rd1];
ld.global.u32 %r44, [%rd1+1024];
ld.global.u32 %r43, [%rd1+2048];
ld.global.u32 %r42, [%rd1+3072];
//
tcgen05.st.sync.aligned.32x32b.x4.b32[%r2],{%r4, %r44, %r43, %r42};

//
//
tcgen05.st.sync.aligned.32x32b.x4.b32[%r24],{%r4, %r44, %r43, %r42};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
setp.gt.u32 %p2, %r1, 127;
@%p2 bra $L__BB0_4;
bar.warp.sync -1;
//
mov.u64 %rd17, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x4.b32{%r29, %r30, %r31, %r32},[%r24];

//
//
tcgen05.ld.sync.aligned.32x32b.x4.b32{%r34, %r35, %r36, %r37},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r39, %r34, %r29;
add.s32 %r45, %r39, %r4;
//
mov.u64 %rd16, %clock64;
//
bra.uni $L__BB0_5;
$L__BB0_4:
mov.b32 %f1, %r4;
add.f32 %f2, %f1, %f1;
mov.b32 %f3, %r44;
add.f32 %f4, %f3, %f3;
mov.b32 %f5, %r43;
add.f32 %f6, %f5, %f5;
mov.b32 %f7, %r42;
add.f32 %f8, %f7, %f7;
mul.f32 %f9, %f2, %f2;
mul.f32 %f10, %f4, %f4;
mul.f32 %f11, %f6, %f6;
mul.f32 %f12, %f8, %f8;
sub.f32 %f13, %f9, %f9;
sub.f32 %f14, %f10, %f10;
sub.f32 %f15, %f11, %f11;
sub.f32 %f16, %f12, %f12;
mul.f32 %f17, %f13, %f13;
mul.f32 %f18, %f14, %f14;
mul.f32 %f19, %f15, %f15;
mul.f32 %f20, %f16, %f16;
sub.f32 %f21, %f17, %f17;
sub.f32 %f22, %f18, %f18;
sub.f32 %f23, %f19, %f19;
sub.f32 %f24, %f20, %f20;
mul.f32 %f25, %f21, %f21;
mov.b32 %r45, %f25;
mul.f32 %f26, %f22, %f22;
mov.b32 %r44, %f26;
mul.f32 %f27, %f23, %f23;
mov.b32 %r43, %f27;
mul.f32 %f28, %f24, %f24;
mov.b32 %r42, %f28;
$L__BB0_5:
setp.gt.u32 %p3, %r1, 31;
bar.sync 0;
@%p3 bra $L__BB0_7;
mov.b32 %r41, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r41; 
}
//
$L__BB0_7:
bar.sync 0;
setp.ne.s32 %p4, %r1, 0;
@%p4 bra $L__BB0_9;
cvta.to.global.u64 %rd14, %rd6;
st.global.u64 [%rd14], %rd17;
cvta.to.global.u64 %rd15, %rd7;
st.global.u64 [%rd15], %rd16;
$L__BB0_9:
st.global.u32 [%rd1], %r45;
st.global.u32 [%rd1+1024], %r44;
st.global.u32 [%rd1+2048], %r43;
st.global.u32 [%rd1+3072], %r42;
ret;

}


Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100a
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100a
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<46>;
.reg .f32 %f<29>;
.reg .b64 %rd<18>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[32768];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd7, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd8, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r17, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r18, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r17], %r18;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r24, %r2, 128;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r4, [%rd1];
ld.global.u32 %r44, [%rd1+1024];
ld.global.u32 %r43, [%rd1+2048];
ld.global.u32 %r42, [%rd1+3072];
//
tcgen05.st.sync.aligned.32x32b.x4.b32[%r2],{%r4, %r44, %r43, %r42};

//
//
tcgen05.st.sync.aligned.32x32b.x4.b32[%r24],{%r4, %r44, %r43, %r42};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
setp.gt.u32 %p2, %r1, 127;
@%p2 bra $L__BB0_4;
bar.warp.sync -1;
//
mov.u64 %rd17, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x4.b32{%r29, %r30, %r31, %r32},[%r24];

//
//
tcgen05.ld.sync.aligned.32x32b.x4.b32{%r34, %r35, %r36, %r37},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r39, %r34, %r29;
add.s32 %r45, %r39, %r4;
//
mov.u64 %rd16, %clock64;
//
bra.uni $L__BB0_5;
$L__BB0_4:
mov.b32 %f1, %r4;
add.f32 %f2, %f1, %f1;
mov.b32 %f3, %r44;
add.f32 %f4, %f3, %f3;
mov.b32 %f5, %r43;
add.f32 %f6, %f5, %f5;
mov.b32 %f7, %r42;
add.f32 %f8, %f7, %f7;
mul.f32 %f9, %f2, %f2;
mul.f32 %f10, %f4, %f4;
mul.f32 %f11, %f6, %f6;
mul.f32 %f12, %f8, %f8;
sub.f32 %f13, %f9, %f9;
sub.f32 %f14, %f10, %f10;
sub.f32 %f15, %f11, %f11;
sub.f32 %f16, %f12, %f12;
mul.f32 %f17, %f13, %f13;
mul.f32 %f18, %f14, %f14;
mul.f32 %f19, %f15, %f15;
mul.f32 %f20, %f16, %f16;
sub.f32 %f21, %f17, %f17;
sub.f32 %f22, %f18, %f18;
sub.f32 %f23, %f19, %f19;
sub.f32 %f24, %f20, %f20;
mul.f32 %f25, %f21, %f21;
mov.b32 %r45, %f25;
mul.f32 %f26, %f22, %f22;
mov.b32 %r44, %f26;
mul.f32 %f27, %f23, %f23;
mov.b32 %r43, %f27;
mul.f32 %f28, %f24, %f24;
mov.b32 %r42, %f28;
$L__BB0_5:
setp.gt.u32 %p3, %r1, 31;
bar.sync 0;
@%p3 bra $L__BB0_7;
mov.b32 %r41, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r41; 
}
//
$L__BB0_7:
bar.sync 0;
setp.ne.s32 %p4, %r1, 0;
@%p4 bra $L__BB0_9;
cvta.to.global.u64 %rd14, %rd6;
st.global.u64 [%rd14], %rd17;
cvta.to.global.u64 %rd15, %rd7;
st.global.u64 [%rd15], %rd16;
$L__BB0_9:
st.global.u32 [%rd1], %r45;
st.global.u32 [%rd1+1024], %r44;
st.global.u32 [%rd1+2048], %r43;
st.global.u32 [%rd1+3072], %r42;
ret;

}

