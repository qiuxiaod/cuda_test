
Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<4>;
.reg .b32 %r<18>;
.reg .b64 %rd<13>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[128];
ld.param.u64 %rd4, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd5, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r5, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r6, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r5], %r6;
//
$L__BB0_2:
setp.gt.u32 %p2, %r1, 31;
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
cvta.to.global.u64 %rd9, %rd6;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r8, [%rd1];
ld.global.u32 %r3, [%rd1+512];
//
tcgen05.st.sync.aligned.32x32b.x2.b32[%r2],{%r8, %r3};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
bar.warp.sync -1;
//
mov.u64 %rd7, %clock64;
//
//
tcgen05.st.sync.aligned.32x32b.x2.b32[%r2],{%r8, %r3};

//
//
tcgen05.wait::st.sync.aligned; 
//
//
tcgen05.ld.sync.aligned.32x32b.x2.b32{%r13, %r14},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r4, %r8, %r13;
//
mov.u64 %rd8, %clock64;
//
bar.sync 0;
@%p2 bra $L__BB0_4;
mov.b32 %r17, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r17; 
}
//
$L__BB0_4:
bar.sync 0;
setp.ne.s32 %p3, %r1, 0;
@%p3 bra $L__BB0_6;
cvta.to.global.u64 %rd11, %rd4;
st.global.u64 [%rd11], %rd7;
cvta.to.global.u64 %rd12, %rd5;
st.global.u64 [%rd12], %rd8;
$L__BB0_6:
st.global.u32 [%rd1], %r4;
st.global.u32 [%rd1+512], %r3;
ret;

}


Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100a
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100a
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<4>;
.reg .b32 %r<18>;
.reg .b64 %rd<13>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[128];
ld.param.u64 %rd4, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd5, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r5, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r6, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r5], %r6;
//
$L__BB0_2:
setp.gt.u32 %p2, %r1, 31;
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
cvta.to.global.u64 %rd9, %rd6;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r8, [%rd1];
ld.global.u32 %r3, [%rd1+512];
//
tcgen05.st.sync.aligned.32x32b.x2.b32[%r2],{%r8, %r3};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
bar.warp.sync -1;
//
mov.u64 %rd7, %clock64;
//
//
tcgen05.st.sync.aligned.32x32b.x2.b32[%r2],{%r8, %r3};

//
//
tcgen05.wait::st.sync.aligned; 
//
//
tcgen05.ld.sync.aligned.32x32b.x2.b32{%r13, %r14},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r4, %r8, %r13;
//
mov.u64 %rd8, %clock64;
//
bar.sync 0;
@%p2 bra $L__BB0_4;
mov.b32 %r17, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r17; 
}
//
$L__BB0_4:
bar.sync 0;
setp.ne.s32 %p3, %r1, 0;
@%p3 bra $L__BB0_6;
cvta.to.global.u64 %rd11, %rd4;
st.global.u64 [%rd11], %rd7;
cvta.to.global.u64 %rd12, %rd5;
st.global.u64 [%rd12], %rd8;
$L__BB0_6:
st.global.u32 [%rd1], %r4;
st.global.u32 [%rd1+512], %r3;
ret;

}

