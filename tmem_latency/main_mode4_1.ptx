
Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<22>;
.reg .f32 %f<8>;
.reg .b64 %rd<18>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[32768];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd7, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd8, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r8, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r9, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r8], %r9;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r12, %r2, 128;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r4, [%rd1];
//
tcgen05.st.sync.aligned.32x32b.x1.b32[%r2],{%r4};

//
//
tcgen05.st.sync.aligned.32x32b.x1.b32[%r12],{%r4};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
setp.gt.u32 %p2, %r1, 127;
@%p2 bra $L__BB0_4;
bar.warp.sync -1;
//
mov.u64 %rd17, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x1.b32{%r14},[%r12];

//
//
tcgen05.ld.sync.aligned.32x32b.x1.b32{%r16},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r18, %r14, %r4;
add.s32 %r21, %r18, %r16;
//
mov.u64 %rd16, %clock64;
//
bra.uni $L__BB0_5;
$L__BB0_4:
mov.b32 %f1, %r4;
add.f32 %f2, %f1, %f1;
mul.f32 %f3, %f2, %f2;
sub.f32 %f4, %f3, %f3;
mul.f32 %f5, %f4, %f4;
sub.f32 %f6, %f5, %f5;
mul.f32 %f7, %f6, %f6;
mov.b32 %r21, %f7;
$L__BB0_5:
setp.gt.u32 %p3, %r1, 31;
bar.sync 0;
@%p3 bra $L__BB0_7;
mov.b32 %r20, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r20; 
}
//
$L__BB0_7:
bar.sync 0;
setp.ne.s32 %p4, %r1, 0;
@%p4 bra $L__BB0_9;
cvta.to.global.u64 %rd14, %rd6;
st.global.u64 [%rd14], %rd17;
cvta.to.global.u64 %rd15, %rd7;
st.global.u64 [%rd15], %rd16;
$L__BB0_9:
st.global.u32 [%rd1], %r21;
ret;

}


Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100a
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100a
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<22>;
.reg .f32 %f<8>;
.reg .b64 %rd<18>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[32768];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd7, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd8, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r8, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r9, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r8], %r9;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r12, %r2, 128;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.u32 %rd10, %r1, 4;
add.s64 %rd1, %rd9, %rd10;
ld.global.u32 %r4, [%rd1];
//
tcgen05.st.sync.aligned.32x32b.x1.b32[%r2],{%r4};

//
//
tcgen05.st.sync.aligned.32x32b.x1.b32[%r12],{%r4};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
setp.gt.u32 %p2, %r1, 127;
@%p2 bra $L__BB0_4;
bar.warp.sync -1;
//
mov.u64 %rd17, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x1.b32{%r14},[%r12];

//
//
tcgen05.ld.sync.aligned.32x32b.x1.b32{%r16},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r18, %r14, %r4;
add.s32 %r21, %r18, %r16;
//
mov.u64 %rd16, %clock64;
//
bra.uni $L__BB0_5;
$L__BB0_4:
mov.b32 %f1, %r4;
add.f32 %f2, %f1, %f1;
mul.f32 %f3, %f2, %f2;
sub.f32 %f4, %f3, %f3;
mul.f32 %f5, %f4, %f4;
sub.f32 %f6, %f5, %f5;
mul.f32 %f7, %f6, %f6;
mov.b32 %r21, %f7;
$L__BB0_5:
setp.gt.u32 %p3, %r1, 31;
bar.sync 0;
@%p3 bra $L__BB0_7;
mov.b32 %r20, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r20; 
}
//
$L__BB0_7:
bar.sync 0;
setp.ne.s32 %p4, %r1, 0;
@%p4 bra $L__BB0_9;
cvta.to.global.u64 %rd14, %rd6;
st.global.u64 [%rd14], %rd17;
cvta.to.global.u64 %rd15, %rd7;
st.global.u64 [%rd15], %rd16;
$L__BB0_9:
st.global.u32 [%rd1], %r21;
ret;

}

