
Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<88>;
.reg .b64 %rd<23>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[33792];
ld.param.u64 %rd4, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd5, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r13, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r14, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r13], %r14;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r24, %r2, 128;
cvta.to.global.u64 %rd7, %rd6;
mul.wide.u32 %rd8, %r1, 4;
add.s64 %rd1, %rd7, %rd8;
ld.global.u32 %r4, [%rd1];
ld.global.u32 %r5, [%rd1+512];
ld.global.u32 %r6, [%rd1+1024];
ld.global.u32 %r7, [%rd1+1536];
ld.global.u32 %r8, [%rd1+2048];
ld.global.u32 %r9, [%rd1+2560];
ld.global.u32 %r10, [%rd1+3072];
ld.global.u32 %r11, [%rd1+3584];
//
tcgen05.st.sync.aligned.32x32b.x8.b32[%r2],{%r4, %r5, %r6, %r7, %r8, %r9, %r10, %r11};

//
//
tcgen05.st.sync.aligned.32x32b.x8.b32[%r24],{%r4, %r5, %r6, %r7, %r8, %r9, %r10, %r11};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
bar.warp.sync -1;
setp.ne.s32 %p2, %r1, 0;
@%p2 bra $L__BB0_4;
mov.u32 %r61, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
shr.u32 %r62, %r61, 4;
and.b32 %r63, %r62, 16383;
cvt.u64.u32 %rd17, %r63;
or.b64 %rd15, %rd17, 4611756662049538048;
add.s32 %r64, %r61, 16384;
shr.u32 %r65, %r64, 4;
and.b32 %r66, %r65, 16383;
cvt.u64.u32 %rd18, %r66;
or.b64 %rd16, %rd18, 4611756662049538048;
mov.b32 %r55, 136314896;
mov.b32 %r56, 1;
mov.b32 %r60, 0;
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
$L__BB0_4:
setp.gt.u32 %p3, %r1, 31;
bar.warp.sync -1;
//
mov.u64 %rd19, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x8.b32{%r67, %r68, %r69, %r70, %r71, %r72, %r73, %r74},[%r24];

//
//
tcgen05.ld.sync.aligned.32x32b.x8.b32{%r76, %r77, %r78, %r79, %r80, %r81, %r82, %r83},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r85, %r76, %r67;
add.s32 %r12, %r85, %r4;
//
mov.u64 %rd20, %clock64;
//
bar.sync 0;
@%p3 bra $L__BB0_6;
mov.b32 %r87, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r87; 
}
//
$L__BB0_6:
setp.ne.s32 %p4, %r1, 0;
bar.sync 0;
@%p4 bra $L__BB0_8;
cvta.to.global.u64 %rd21, %rd4;
st.global.u64 [%rd21], %rd19;
cvta.to.global.u64 %rd22, %rd5;
st.global.u64 [%rd22], %rd20;
$L__BB0_8:
st.global.u32 [%rd1], %r12;
st.global.u32 [%rd1+512], %r5;
st.global.u32 [%rd1+1024], %r6;
st.global.u32 [%rd1+1536], %r7;
st.global.u32 [%rd1+2048], %r8;
st.global.u32 [%rd1+2560], %r9;
st.global.u32 [%rd1+3072], %r10;
st.global.u32 [%rd1+3584], %r11;
ret;

}


Fatbin elf code:
================
arch = sm_100a
code version = [1,8]
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_100a
code version = [8,7]
host = linux
compile_size = 64bit
compressed
ptxasOptions = -O3  

//
//
//
//
//
//

.version 8.7
.target sm_100a
.address_size 64

//
//

.visible .entry _Z24benchmarkTMEMLoadLatencyPyS_Pj(
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1,
.param .u64 _Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2
)
{
.reg .pred %p<5>;
.reg .b32 %r<88>;
.reg .b64 %rd<23>;
//
.shared .align 4 .b8 _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem[33792];
ld.param.u64 %rd4, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_0];
ld.param.u64 %rd5, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_1];
ld.param.u64 %rd6, [_Z24benchmarkTMEMLoadLatencyPyS_Pj_param_2];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 31;
@%p1 bra $L__BB0_2;
mov.u32 %r13, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
mov.b32 %r14, 512;
//
tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r13], %r14;
//
$L__BB0_2:
bar.sync 0;
ld.shared.u32 %r2, [_ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem];
add.s32 %r24, %r2, 128;
cvta.to.global.u64 %rd7, %rd6;
mul.wide.u32 %rd8, %r1, 4;
add.s64 %rd1, %rd7, %rd8;
ld.global.u32 %r4, [%rd1];
ld.global.u32 %r5, [%rd1+512];
ld.global.u32 %r6, [%rd1+1024];
ld.global.u32 %r7, [%rd1+1536];
ld.global.u32 %r8, [%rd1+2048];
ld.global.u32 %r9, [%rd1+2560];
ld.global.u32 %r10, [%rd1+3072];
ld.global.u32 %r11, [%rd1+3584];
//
tcgen05.st.sync.aligned.32x32b.x8.b32[%r2],{%r4, %r5, %r6, %r7, %r8, %r9, %r10, %r11};

//
//
tcgen05.st.sync.aligned.32x32b.x8.b32[%r24],{%r4, %r5, %r6, %r7, %r8, %r9, %r10, %r11};

//
//
tcgen05.wait::st.sync.aligned; 
//
bar.sync 0;
bar.sync 0;
bar.warp.sync -1;
setp.ne.s32 %p2, %r1, 0;
@%p2 bra $L__BB0_4;
mov.u32 %r61, _ZZ24benchmarkTMEMLoadLatencyPyS_PjE9sharedMem;
shr.u32 %r62, %r61, 4;
and.b32 %r63, %r62, 16383;
cvt.u64.u32 %rd17, %r63;
or.b64 %rd15, %rd17, 4611756662049538048;
add.s32 %r64, %r61, 16384;
shr.u32 %r65, %r64, 4;
and.b32 %r66, %r65, 16383;
cvt.u64.u32 %rd18, %r66;
or.b64 %rd16, %rd18, 4611756662049538048;
mov.b32 %r55, 136314896;
mov.b32 %r56, 1;
mov.b32 %r60, 0;
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
//
{
.reg .pred p;
setp.ne.b32 p, %r56, 0;
tcgen05.mma.cta_group::1.kind::f16 [%r2], %rd15, %rd16, %r55, {%r60, %r60, %r60, %r60}, p; 
}

//
$L__BB0_4:
setp.gt.u32 %p3, %r1, 31;
bar.warp.sync -1;
//
mov.u64 %rd19, %clock64;
//
//
tcgen05.ld.sync.aligned.32x32b.x8.b32{%r67, %r68, %r69, %r70, %r71, %r72, %r73, %r74},[%r24];

//
//
tcgen05.ld.sync.aligned.32x32b.x8.b32{%r76, %r77, %r78, %r79, %r80, %r81, %r82, %r83},[%r2];

//
//
tcgen05.wait::ld.sync.aligned; 
//
add.s32 %r85, %r76, %r67;
add.s32 %r12, %r85, %r4;
//
mov.u64 %rd20, %clock64;
//
bar.sync 0;
@%p3 bra $L__BB0_6;
mov.b32 %r87, 512;
//
{
tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r2, %r87; 
}
//
$L__BB0_6:
setp.ne.s32 %p4, %r1, 0;
bar.sync 0;
@%p4 bra $L__BB0_8;
cvta.to.global.u64 %rd21, %rd4;
st.global.u64 [%rd21], %rd19;
cvta.to.global.u64 %rd22, %rd5;
st.global.u64 [%rd22], %rd20;
$L__BB0_8:
st.global.u32 [%rd1], %r12;
st.global.u32 [%rd1+512], %r5;
st.global.u32 [%rd1+1024], %r6;
st.global.u32 [%rd1+1536], %r7;
st.global.u32 [%rd1+2048], %r8;
st.global.u32 [%rd1+2560], %r9;
st.global.u32 [%rd1+3072], %r10;
st.global.u32 [%rd1+3584], %r11;
ret;

}

